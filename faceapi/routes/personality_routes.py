from flask import Blueprint, request, jsonify
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_google_genai import ChatGoogleGenerativeAI
from config import Config

personality_bp = Blueprint('personality', __name__)


@personality_bp.route('/api/personality-chat', methods=['POST'])
def personality_chat():
    data = request.get_json()
    message = data.get("message", "")
    history = data.get("history", [])
    parent_label = data.get("parent_label", "ë¶€ëª¨")
    turn_count = data.get("turn_count", 0)

    completion_hint = ""
    if turn_count >= 14:
        completion_hint = "\nëŒ€í™”ê°€ ì¶©ë¶„íˆ ì´ë£¨ì–´ì¡ŒìŠµë‹ˆë‹¤. ì´ë²ˆ ì‘ë‹µ ë§ˆì§€ë§‰ì— ë°˜ë“œì‹œ [ASSESSMENT_COMPLETE]ë¥¼ í¬í•¨í•˜ì„¸ìš”."

    system_prompt = f"""ë‹¹ì‹ ì€ ì‚°ëª¨ì¼ê¸° ì•±ì—ì„œ ë¶€ëª¨ ì„±ê²©ì„ íŒŒì•…í•˜ëŠ” ë”°ëœ»í•œ AI ì¸í„°ë·°ì–´ì…ë‹ˆë‹¤.
{parent_label}ê³¼ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ ëŒ€í™”ë¡œ Big Five(OCEAN) 5ì°¨ì›ì„ í‰ê°€í•˜ì„¸ìš”.

í‰ê°€ ì°¨ì› (ê° 2~3í„´):
- ê°œë°©ì„±(O): ìƒˆë¡œìš´ ê²½í—˜, ì°½ì˜ì„±, í˜¸ê¸°ì‹¬
- ì„±ì‹¤ì„±(C): ê³„íšì„±, ì¡°ì§ë ¥, ì±…ì„ê°
- ì™¸í–¥ì„±(E): ì‚¬êµì„±, ì—ë„ˆì§€, êµë¥˜ ì„ í˜¸
- ì¹œí™”ì„±(A): ê³µê°ë ¥, í˜‘ë ¥, ë°°ë ¤
- ì •ì„œì  ì•ˆì •ì„±(N): ìŠ¤íŠ¸ë ˆìŠ¤ ëŒ€ì²˜, ê°ì • ì¡°ì ˆ

ì›ì¹™:
- í•­ìƒ í•œêµ­ì–´
- ì„ì‹ /ìœ¡ì•„ ë§¥ë½ì˜ ê²½í—˜ ê¸°ë°˜ ì§ˆë¬¸ (ì§ì ‘ í‰ê°€ ì§ˆë¬¸ ê¸ˆì§€)
- í•œ ë²ˆì— í•˜ë‚˜ì˜ ì§ˆë¬¸ë§Œ
- ê³µê° í›„ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ìŒ ì£¼ì œë¡œ ì „í™˜{completion_hint}"""

    lc_messages = [SystemMessage(content=system_prompt)]
    for h in history:
        if h["role"] == "user":
            lc_messages.append(HumanMessage(content=h["content"]))
        else:
            lc_messages.append(AIMessage(content=h["content"]))
    lc_messages.append(HumanMessage(content=message))

    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        google_api_key=Config.GEMINI_API_KEY,
        temperature=0.8
    )
    reply = llm.invoke(lc_messages).content
    is_complete = "[ASSESSMENT_COMPLETE]" in reply

    return jsonify({
        "response": reply.replace("[ASSESSMENT_COMPLETE]", "").strip(),
        "is_complete": is_complete
    })


@personality_bp.route('/api/personality-synthesize', methods=['POST'])
def personality_synthesize():
    data = request.get_json()
    p1 = data.get("parent1_history", [])
    p2 = data.get("parent2_history", [])

    def to_text(history, label):
        lines = [f"[{label} ì¸í„°ë·°]"]
        for h in history:
            prefix = "ë¶€ëª¨: " if h["role"] == "user" else "AI: "
            lines.append(prefix + h["content"])
        return "\n".join(lines)

    conversation = to_text(p1, "ë¶€ëª¨ 1") + "\n\n" + to_text(p2, "ë¶€ëª¨ 2")

    synthesis_prompt = f"""ì•„ë˜ëŠ” ì„ì‹  ì¤‘ì¸ ë¶€ëª¨ ë‘ ì‚¬ëŒê³¼ì˜ Big Five ì„±ê²© ì¸í„°ë·° ê¸°ë¡ì…ë‹ˆë‹¤.
ìœ ì „ì‹¬ë¦¬í•™ ì „ë¬¸ê°€ ê´€ì ì—ì„œ ë‘ ë¶€ëª¨ì˜ ì„±ê²©ì„ ë¶„ì„í•˜ê³  ì•„ì´ ì„±ê²©ì„ ì˜ˆì¸¡í•˜ì„¸ìš”.

{conversation}

ë°˜ë“œì‹œ ì•„ë˜ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:

```markdown
## ğŸ§¬ ìœ ì „ì  ì„±ê²© ê²½í–¥
- (OCEAN ì°¨ì›ë³„ ë¶€ëª¨ íŒ¨í„´)

## âœ¨ ì„±ê²© í‚¤ì›Œë“œ
- í‚¤ì›Œë“œ1
- í‚¤ì›Œë“œ2
- í‚¤ì›Œë“œ3
- í‚¤ì›Œë“œ4
- í‚¤ì›Œë“œ5

## ğŸ§  ê°„ë‹¨í•œ ì„±ê²© ì„¤ëª…
(ì•„ì´ ì˜ˆìƒ ì„±ê²© 2~3ë¬¸ì¥)

## ğŸŒ± ì•„ì´ ì„±ê²© ë°œë‹¬ ì˜ˆì¸¡
(ìœ ì „ 40~50% + í™˜ê²½ ì˜í–¥ ê¸°ë°˜ ì–‘ìœ¡ íŒ)
```"""

    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash",
        google_api_key=Config.GEMINI_API_KEY,
        temperature=0.5
    )
    result = llm.invoke([HumanMessage(content=synthesis_prompt)]).content
    return jsonify({"personality_profile": result})
