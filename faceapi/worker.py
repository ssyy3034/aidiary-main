import pika
import os
import time
import json
import logging
import base64
import requests
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("ImageWorker")

# í™˜ê²½ ë³€ìˆ˜ ê°€ê³µ
RABBITMQ_HOST = os.environ.get('RABBITMQ_HOST', 'localhost')
RABBITMQ_PORT = int(os.environ.get('RABBITMQ_PORT', 5672))
RABBITMQ_USER = os.environ.get('RABBITMQ_DEFAULT_USER', 'guest')
RABBITMQ_PASS = os.environ.get('RABBITMQ_DEFAULT_PASS', 'guest')
WEBHOOK_URL = os.environ.get('SPRING_WEBHOOK_URL', 'http://host.docker.internal:8080/api/images/webhook')
SPRING_BASE_URL = WEBHOOK_URL.rsplit('/api/images/webhook', 1)[0]
QUEUE_NAME = 'image-processing'

# Lazy load ImageGenerator to save memory on boot if needed
image_generator = None

def get_image_generator():
    global image_generator
    if image_generator is None:
        logger.info("Initializing Heavy ML Models (ImageGenerator)...")
        from services.image_generator import ImageGenerator
        image_generator = ImageGenerator()
    return image_generator

def check_already_processed(job_id):
    """ë©±ë“±ì„± ê°€ë“œ: Spring Bootì— statusë¥¼ ì¡°íšŒí•´ ì´ë¯¸ ì™„ë£Œëœ ì‘ì—…ì¸ì§€ í™•ì¸."""
    try:
        resp = requests.get(f"{SPRING_BASE_URL}/api/images/status/{job_id}", timeout=3)
        if resp.status_code == 200:
            return resp.json().get('status') in ('DONE', 'FAILED')
    except Exception as e:
        logger.warning(f"[Idempotency] Status check failed for {job_id}: {e}")
    return False

def process_message(ch, method, properties, body):
    job_id = "UNKNOWN"
    try:
        # 1. ë©”ì‹œì§€ íŒŒì‹±
        # Spring Bootì˜ Jackson2JsonMessageConverterê°€ ì „ì†¡í•œ JSON íŒŒì‹±
        message_data = json.loads(body.decode('utf-8'))
        job_id = message_data.get('jobId')

        logger.info(f"ğŸ“¥ Received Job: {job_id}")

        # ë©±ë“±ì„± ê°€ë“œ: RabbitMQ at-least-once deliveryë¡œ ì¸í•œ ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€ (~30ì´ˆ ì—°ì‚° ë‚­ë¹„ ì°¨ë‹¨)
        if check_already_processed(job_id):
            logger.info(f"[Idempotency] Job {job_id} already processed. ACK and skip.")
            ch.basic_ack(delivery_tag=method.delivery_tag)
            return

        # Base64 ì¸ì½”ë”©ëœ íŒŒì¼ ë°”ì´íŠ¸ ë””ì½”ë”© ì„ì‹œ ì €ì¥ íŒŒì¼ë¡œ ë³€í™˜
        parent1_bytes = base64.b64decode(message_data.get('parent1Bytes'))
        parent2_bytes = base64.b64decode(message_data.get('parent2Bytes'))
        parent1_name = message_data.get('parent1Name', 'parent1.jpg')
        parent2_name = message_data.get('parent2Name', 'parent2.jpg')

        # ì„ì‹œ ì‘ì—… í´ë” ìƒì„±
        os.makedirs('/tmp/faceapi_jobs', exist_ok=True)
        p1_path = f"/tmp/faceapi_jobs/{job_id}_{parent1_name}"
        p2_path = f"/tmp/faceapi_jobs/{job_id}_{parent2_name}"

        with open(p1_path, 'wb') as f:
            f.write(parent1_bytes)
        with open(p2_path, 'wb') as f:
            f.write(parent2_bytes)

        # 2. ML íŒŒì´í”„ë¼ì¸ ì—°ì‚° (ImageGenerator í™œìš©)
        generator = get_image_generator()
        result = generator.process_image_generation(p1_path, p2_path)

        # 3. Webhookìœ¼ë¡œ ë°±ì—”ë“œ(Spring Boot)ì— ê²°ê³¼ ë¦¬í„´
        if result.get("success"):
            logger.info(f"âœ… Job {job_id} ML Processing Success. Sending to Webhook...")
            image_path = result.get("image_path")

            with open(image_path, 'rb') as img_file:
                files = {'image': (os.path.basename(image_path), img_file, 'image/png')}
                data = {'jobId': job_id, 'status': 'SUCCESS'}
                resp = requests.post(WEBHOOK_URL, data=data, files=files)

            if resp.status_code == 200:
                logger.info(f"ğŸ‰ Webhook transmission success for {job_id}")
            else:
                logger.error(f"âŒ Webhook returned {resp.status_code}: {resp.text}")
        else:
            logger.error(f"âš ï¸ ML Pipeline Failed for {job_id}: {result.get('error')}")
            send_failure_webhook(job_id, result.get("error"))

    except Exception as e:
        logger.error(f"âŒ Critical Worker Error on Job {job_id}: {str(e)}")
        send_failure_webhook(job_id, str(e))
    finally:
        # ë©”ì‹œì§€ ì²˜ë¦¬ ì™„ë£Œ ACK ì „ì†¡
        logger.info(f"âœ… Sending ACK for {job_id}")
        ch.basic_ack(delivery_tag=method.delivery_tag)

        # íŒŒì¼ ì •ë¦¬
        try:
            if 'p1_path' in locals() and os.path.exists(p1_path): os.remove(p1_path)
            if 'p2_path' in locals() and os.path.exists(p2_path): os.remove(p2_path)
        except Exception:
            pass

def send_failure_webhook(job_id, error_msg):
    try:
        data = {'jobId': job_id, 'status': 'FAILED', 'error': error_msg}
        requests.post(WEBHOOK_URL, data=data)
    except Exception as e:
        logger.error(f"Failed to send failure webhook for {job_id}: {e}")

def main():
    logger.info("ğŸš€ Starting Face API RabbitMQ Worker...")

    # RabbitMQê°€ ì™„ì „íˆ ëœ° ë•Œê¹Œì§€ ëŒ€ê¸°
    connection = None
    retry_count = 0
    while connection is None and retry_count < 10:
        try:
            credentials = pika.PlainCredentials(RABBITMQ_USER, RABBITMQ_PASS)
            parameters = pika.ConnectionParameters(
                host=RABBITMQ_HOST,
                port=RABBITMQ_PORT,
                credentials=credentials,
                # Heartbeat ì²˜ë¦¬ë¥¼ ê¸¸ê²Œ ë‘ì–´ ë¬´ê±°ìš´ ML ì‘ì—… ë„ì¤‘ ëŠê¸°ì§€ ì•Šë„ë¡ ë°©ì§€
                heartbeat=600,
                blocked_connection_timeout=300
            )
            connection = pika.BlockingConnection(parameters)
        except pika.exceptions.AMQPConnectionError:
            logger.warning(f"RabbitMQ not ready. Retrying in 5 seconds... ({retry_count}/10)")
            retry_count += 1
            time.sleep(5)

    if not connection:
        logger.error("âŒ Failed to connect to RabbitMQ. Exiting.")
        return

    channel = connection.channel()

    # íê°€ ì¡´ì¬í•˜ë„ë¡ ê°•ì œ (durable=True)
    channel.queue_declare(queue=QUEUE_NAME, durable=True, arguments={
        'x-dead-letter-exchange': 'image-exchange.dlx',
        'x-dead-letter-routing-key': 'image-processing.dlq'
    })

    # ê³µì • ë¶„ë°°: í•œ ì›Œì»¤ë‹¹ í•œ ë²ˆì— 1ê°œì˜ ë©”ì‹œì§€ë§Œ ê°€ì ¸ê°
    channel.basic_qos(prefetch_count=1)

    # ì½œë°± ë“±ë¡ (auto_ack=False ë¡œ ì„¤ì •í•´ ìˆ˜ë™ ì„±ê³µ ì²˜ë¦¬)
    channel.basic_consume(queue=QUEUE_NAME, on_message_callback=process_message, auto_ack=False)

    logger.info(f"ğŸ§ Ready to consume messages from '{QUEUE_NAME}'. Waiting for tasks...")
    try:
        channel.start_consuming()
    except KeyboardInterrupt:
        logger.info("Stopping Worker...")
        channel.stop_consuming()
    finally:
        connection.close()

if __name__ == '__main__':
    main()
