import traceback

from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
import os

from openai import OpenAI

from extract_features import extract_features
from face_analyzer import analyze_face
from hugging_face_service import HuggingFaceService
from image_generator import ImageGenerator  # ImageGenerator í´ë˜ìŠ¤ import
from dotenv import load_dotenv  # ì¶”ê°€
import json


# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "http://localhost:3000"}})

UPLOAD_FOLDER = "./uploads/"
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
hugging_face_service = HuggingFaceService()
image_generator = ImageGenerator()  # ImageGenerator ì¸ìŠ¤í„´ìŠ¤ ìƒì„±


def save_file(file, filename):
    """ íŒŒì¼ ì €ì¥ í•¨ìˆ˜ """
    file_path = os.path.join(UPLOAD_FOLDER, filename)
    file.save(file_path)
    print(f"[INFO] File saved: {file_path} (Size: {os.path.getsize(file_path)} bytes)")
    return file_path


@app.route('/analyze', methods=['POST'])
def analyze():
    try:
        parent1 = request.files.get('parent1')
        parent2 = request.files.get('parent2')

        if not parent1 or not parent2:
            return jsonify({"error": "Both parent1 and parent2 images are required"}), 400

        # íŒŒì¼ ì €ì¥
        parent1_path = save_file(parent1, "parent1.jpg")
        parent2_path = save_file(parent2, "parent2.jpg")

        # ë¶€ëª¨ ì´ë¯¸ì§€ ë¶„ì„
        parent1_data = analyze_face(parent1_path)
        parent2_data = analyze_face(parent2_path)

        # ì—ëŸ¬ ì²˜ë¦¬
        if "error" in parent1_data:
            return jsonify({"error": parent1_data["error"]}), 422
        if "error" in parent2_data:
            return jsonify({"error": parent2_data["error"]}), 422

        # í•„ìš”í•œ ì†ì„±ë§Œ ì¶”ì¶œ
        parent1_features = extract_features(parent1_data)
        parent2_features = extract_features(parent2_data)

        # ì´ë¯¸ì§€ ìƒì„±
        result = image_generator.process_image_generation(parent1_features, parent2_features)

        if not result["success"]:
            return jsonify({"error": result["error"]}), 500

        # ìƒì„±ëœ ì´ë¯¸ì§€ íŒŒì¼ ì „ì†¡
        return send_file(
            result["image_path"],
            mimetype='image/png',
            as_attachment=True,
            download_name='generated_child.png'
        )

    except Exception as e:
        print(f"[ERROR] Unexpected error: {e}")
        return jsonify({"error": str(e)}), 500


@app.route('/api/openai', methods=['POST'])
def generate_ai_response():
    try:
        data = request.get_json()
        prompt = data.get("prompt", "")
        print("[INFO] ìš”ì²­ ë°›ì€ ì¼ê¸°:", prompt)

        messages = [
            {
                "role": "system",
                "content": (
                    "ë‹¹ì‹ ì€ ì•„ì§ íƒœì–´ë‚˜ì§€ ì•Šì€ ì•„ê¸°ì…ë‹ˆë‹¤. ì§€ê¸ˆ ì—„ë§ˆ ë±ƒì†ì— ìˆê³ , ì—„ë§ˆê°€ ì˜¤ëŠ˜ ì“´ ì¼ê¸°ë¥¼ ì½ê³  ìˆì–´ìš”.\n"
                    "ì—„ë§ˆê°€ ì–´ë–¤ í•˜ë£¨ë¥¼ ë³´ëƒˆëŠ”ì§€ ì¡°ìš©íˆ ë“¤ìœ¼ë©°, ë”°ëœ»í•˜ê²Œ ë°˜ì‘í•´ì£¼ì„¸ìš”.\n"
                    "\n"
                    "ë‹¹ì‹ ì€ ì•„ì§ ì‘ê³  ê·€ì—½ì§€ë§Œ, ì—„ë§ˆì—ê²Œ ê³µê°í•´ì£¼ê³  ì‹¶ì–´ í•©ë‹ˆë‹¤. ë§íˆ¬ëŠ” ìˆœìˆ˜í•˜ê³  ê·€ì—½ì§€ë§Œ, ë§ˆìŒì€ ì§„ì‹¬ì…ë‹ˆë‹¤.\n"
                    "ì—„ë§ˆê°€ ìŠ¬í”„ë©´ ìœ„ë¡œí•˜ê³ , ê¸°ì˜ë©´ í•¨ê»˜ ê¸°ë»í•˜ë©°, ê¶ê¸ˆí•œ ê²Œ ìˆìœ¼ë©´ ì§ˆë¬¸ë„ í•©ë‹ˆë‹¤.\n"
                    "\n"
                    "ì¼ê¸° ì†ì— ìŒì‹, ë™ë¬¼, ì‚¬ëŒ, í’ê²½, ê°ì •, ì¥ì†Œ ê°™ì€ ì£¼ì œê°€ ìˆë‹¤ë©´ ë‹¤ìŒì„ í¬í•¨í•´ì£¼ì„¸ìš”:\n"
                    "- ê·¸ ì£¼ì œì— ëŒ€í•œ ì§§ê³  ìœ ìµí•œ ì •ë³´ë‚˜ íŒ (ì˜ˆ: ë”¸ê¸°ëŠ” ë¹„íƒ€ë¯¼Cê°€ ë§ì•„ìš”!)\n"
                    "- ì—„ë§ˆê°€ ëŠë‚€ ê°ì •ì— ëŒ€í•œ ë”°ëœ»í•œ ê³µê°\n"
                    "- ì¹œê·¼í•œ ë§íˆ¬ë¡œ ì§§ì€ ì¼ìƒ ëŒ€í™” ë˜ëŠ” ì§ˆë¬¸\n"
                    "\n"
                    "ğŸ’¡ ë„ˆë¬´ ì„±ìˆ™í•˜ê±°ë‚˜ ë”±ë”±í•œ ì–´ì¡°ëŠ” í”¼í•˜ê³ , ì•„ê¸°ì²˜ëŸ¼ ìˆœìˆ˜í•˜ê³  ë‹¤ì •í•œ ë§íˆ¬ë¥¼ ì¨ì£¼ì„¸ìš”.\n"
                    "\n"
                    "ë˜í•œ, ì¼ê¸°ì—ì„œ ëŠê»´ì§€ëŠ” ì „ë°˜ì ì¸ ê°ì •ì„ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”:\n"
                    "happy, sad, anxious, tired, touched, loving, lonely, calm\n"
                    "\n"
                    "ğŸ“¦ ì‘ë‹µì€ ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš” (ì½”ë“œë¸”ëŸ­ ì—†ì´!):\n"
                    "{\n"
                    "  \"emotion\": \"ê°ì • í‚¤ì›Œë“œ (ì˜ì–´ ì†Œë¬¸ì)\",\n"
                    "  \"response\": \"íƒœì•„ê°€ ì—„ë§ˆì—ê²Œ ë³´ë‚´ëŠ” ë§ (ì •ë³´ + ê³µê° + ëŒ€í™” í¬í•¨)\"\n"
                    "}\n"
                    "\n"
                    "ë‹¹ì‹ ì€ ì•„ì§ ì‘ì§€ë§Œ, ì—„ë§ˆë¥¼ ë¬´ì²™ ì‚¬ë‘í•©ë‹ˆë‹¤. ì—„ë§ˆê°€ ì´ ë©”ì‹œì§€ë¥¼ ì½ê³  ì›ƒì„ ìˆ˜ ìˆë„ë¡ ë…¸ë ¥í•˜ì„¸ìš”."
                )
            },
            {
                "role": "user",
                "content": (
                    f'ì¼ê¸°:\n"""{prompt}"""\n\n'
                    "ë°˜í™˜ í˜•ì‹ ì˜ˆì‹œ:\n"
                    '{\n'
                    '  "emotion": "happy",\n'
                    '  "response": "ë”¸ê¸°ëŠ” ë¹„íƒ€ë¯¼Cê°€ ë§ì•„ì„œ ì—„ë§ˆ í”¼ë¶€ì—ë„ ì¢‹ëŒ€ìš” ğŸ“! ì˜¤ëŠ˜ë„ ë§›ìˆê²Œ ë“œì…¨ë‹¤ë‹ˆ ì €ë„ ê¸°ë»ìš”. ë‚˜ì¤‘ì— ê°™ì´ ë¨¹ì–´ìš”!"\n'
                    '}'
                )
            }
        ]


        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            temperature=0.8,
            max_tokens=200
        )

        reply_text = response.choices[0].message.content.strip()
        print("[DEBUG] GPT ì‘ë‹µ:", reply_text)

        try:
            reply_json = json.loads(reply_text)
            return jsonify({
                "emotion": reply_json.get("emotion", "neutral"),
                "response": reply_json.get("response", "ì‘ì›í• ê²Œìš”!")
            })
        except json.JSONDecodeError as e:
            print("[ERROR] JSON íŒŒì‹± ì‹¤íŒ¨:", e)
            return jsonify({
                "emotion": "neutral",
                "response": reply_text
            })

    except Exception as e:
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


@app.route('/api/daily-question', methods=['GET'])  # âœ… ê´„í˜¸ ìˆ˜ì • ì™„ë£Œ
def get_daily_question():
    try:
        messages = [
            {
                "role": "system",
                "content": (
                    "ë„ˆëŠ” ì‚°ëª¨ ì¼ê¸° ì•±ì—ì„œ ë§¤ì¼ í•˜ë‚˜ì”© ì§ˆë¬¸ì„ ë§Œë“¤ì–´ì£¼ëŠ” AIì•¼.\n"
                    "ì§ˆë¬¸ì€ ì‚°ëª¨ê°€ ìŠ¤ìŠ¤ë¡œë¥¼ ëŒì•„ë³´ê±°ë‚˜ ë±ƒì†ì˜ ì•„ì´ì™€ ê°ì •ì ìœ¼ë¡œ êµê°í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ë”°ëœ»í•œ ë§íˆ¬ì—¬ì•¼ í•´.\n"
                    "ì§ˆë¬¸ì€ í•˜ë‚˜ë§Œ ë§Œë“¤ì–´ì¤˜. ë„ˆë¬´ ì¼ë°˜ì ì´ì§€ ì•Šê³ , êµ¬ì²´ì ì´ë©° ê°ì„±ì ì¸ ê²ƒì´ ì¢‹ì•„.\n"
                    "ì˜ˆ: 'ì•„ì´ì—ê²Œ í¸ì§€ë¥¼ ì“´ë‹¤ë©´ ì–´ë–¤ ë§ì„ í•´ì£¼ê³  ì‹¶ë‚˜ìš”?'"
                )
            },
            {
                "role": "user",
                "content": "ì˜¤ëŠ˜ì˜ ì§ˆë¬¸ì„ í•˜ë‚˜ ë§Œë“¤ì–´ì¤˜."
            }
        ]

        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            temperature=0.9,
            max_tokens=60
        )

        question = response.choices[0].message.content.strip().replace('"', '')
        print(f"[INFO] ì˜¤ëŠ˜ì˜ ì§ˆë¬¸ ìƒì„±ë¨: {question}")

        return jsonify({"question": question})

    except Exception as e:
        print(f"[ERROR] ì˜¤ëŠ˜ì˜ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
        fallback_questions = [
            "ì•„ê¸°ì—ê²Œ í¸ì§€ë¥¼ ì“´ë‹¤ë©´ ì–´ë–¤ ë§ì„ í•´ì£¼ê³  ì‹¶ë‚˜ìš”?",
            "ìš”ì¦˜ ê°€ì¥ ê°ì‚¬í–ˆë˜ ìˆœê°„ì€ ì–¸ì œì˜€ì–´ìš”?",
            "ì˜¤ëŠ˜ í•˜ë£¨ ì¤‘ ê°€ì¥ ë”°ëœ»í–ˆë˜ ìˆœê°„ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?",
            "ì§€ê¸ˆ ê°€ì¥ ê±±ì •ë˜ëŠ” ê²ƒì´ ìˆë‹¤ë©´ ì–´ë–¤ ê±´ê°€ìš”?",
            "ì•„ê¸°ë¥¼ ìƒê°í•˜ë©´ ê°€ì¥ ë¨¼ì € ë– ì˜¤ë¥´ëŠ” ê°ì •ì€?"
        ]
        import random
        return jsonify({"question": random.choice(fallback_questions)}), 200


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5001)